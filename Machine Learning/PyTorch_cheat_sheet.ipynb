{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch cheat sheet ",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4MImohcQUiH"
      },
      "source": [
        "# **Pytorch cheat sheet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWnKc11FEWuh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d234dc96-db68-4db6-a192-aa9901e5762e"
      },
      "source": [
        "import torch                # importing PyTorch \n",
        "print(torch.__version__)    # check for PyTorch version \n",
        "#device = \"cuda\" if torch.cuda.is_avalable() else \"cpu\"  # used to check device for computation, not a advisable command on google colab  \n",
        "device = \"cpu\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tjczj10PgPc"
      },
      "source": [
        "Creating the first Tensor and it's properties"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwDPYHh8IQR-",
        "outputId": "695aa0bf-5ef9-4052-c9b6-8d09025b424e"
      },
      "source": [
        "#Creating Tensor \n",
        "\n",
        "my_torch = torch.tensor([[1,2,3],[4,5,6]], dtype =  torch.float32 , device ='cpu',requires_grad = True)\n",
        "# required grad is used when we used backprop \n",
        "\n",
        "print(my_torch)#Printing my tensor\n",
        "\n",
        "print(my_torch.dtype)#printing datatype of tensor \n",
        "\n",
        "print(my_torch.device)#Printing the device name used for processing \n",
        "\n",
        "print(my_torch.shape)#Print the tensor shape \n",
        "\n",
        "print(my_torch.requires_grad)#print fi ti requires grad or not "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], requires_grad=True)\n",
            "torch.float32\n",
            "cpu\n",
            "torch.Size([2, 3])\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLv3rfsseutz"
      },
      "source": [
        "Other common initiation methods "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ml5eeipIjSZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9ca48e3-727c-4a7f-c366-2c502639b1a1"
      },
      "source": [
        "x = torch.empty(size =(3,3))  #Tensor would have garbage values at all it's parts which would be random \n",
        "print(x)\n",
        "x = torch.zeros((3,3))\n",
        "print(x)\n",
        "x = torch.rand((3,3))  # Normal distribution from 0,1\n",
        "print(x)\n",
        "x = torch.ones((3,3))\n",
        "print(x)\n",
        "x = torch.eye(3,3) # Identity matrix , no double brackets in identity matrices \n",
        "print(x)\n",
        "x = torch.arange(start = 0 ,end =5,step =0.5) #inclusive start exclusive end \n",
        "print(x)\n",
        "x = torch.linspace(start= 0 ,end =5 ,steps =10) # inclusive start inclusive ned with steps number of points \n",
        "print(x)\n",
        "x = torch.empty(size =(1,5)).normal_(mean =0, std =1) # distribute data from 1 to 5 with a standard deviation of 1 \n",
        "print(x)\n",
        "x = torch.empty(size = (1,5)).uniform_(0,1)\n",
        "print(x)\n",
        "x = torch.diag(torch.ones(3)) # all the diagonal elements would be one or as mentioned in the inner dimention \n",
        "print(x)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[7.6639e+26, 3.0855e-41, 3.3631e-44],\n",
            "        [0.0000e+00,        nan, 0.0000e+00],\n",
            "        [1.1578e+27, 1.1362e+30, 7.1547e+22]])\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([[0.9637, 0.1056, 0.2356],\n",
            "        [0.5305, 0.7225, 0.8348],\n",
            "        [0.4060, 0.4815, 0.3171]])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]])\n",
            "tensor([0.0000, 0.5000, 1.0000, 1.5000, 2.0000, 2.5000, 3.0000, 3.5000, 4.0000,\n",
            "        4.5000])\n",
            "tensor([0.0000, 0.5556, 1.1111, 1.6667, 2.2222, 2.7778, 3.3333, 3.8889, 4.4444,\n",
            "        5.0000])\n",
            "tensor([[ 0.6643, -1.1021,  0.3778,  0.2979, -0.7050]])\n",
            "tensor([[0.8683, 0.8613, 0.5116, 0.1604, 0.2206]])\n",
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO9Q283atD7f"
      },
      "source": [
        "How to initialize and convert tensor to other types (int float and double )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvfELXERe8WG",
        "outputId": "97dc6c4a-2c7d-4a55-eb5d-0c6ae5b39dbd"
      },
      "source": [
        "tensor = torch.arange(4)\n",
        "print(tensor)\n",
        "print(tensor.bool()) #applies boolean operator\n",
        "print(tensor.short()) #convert to int16\n",
        "print(tensor.long()) # to int64\n",
        "print(tensor.half()) # to float16\n",
        "print(tensor.float()) #float 32bit \n",
        "print(tensor.double())#float64"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 3])\n",
            "tensor([False,  True,  True,  True])\n",
            "tensor([0, 1, 2, 3], dtype=torch.int16)\n",
            "tensor([0, 1, 2, 3])\n",
            "tensor([0., 1., 2., 3.], dtype=torch.float16)\n",
            "tensor([0., 1., 2., 3.])\n",
            "tensor([0., 1., 2., 3.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cunLb2Y8uDBD"
      },
      "source": [
        "Array to tensor conversion and vice versa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZwBZBistVeQ"
      },
      "source": [
        "import numpy as np \n",
        "np_array = np.zeros((5,5)) # numpy array of 5x5\n",
        "tensor = torch.from_numpy(np_array)\n",
        "np_array_back = tensor.numpy()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI0WSiNZuwbF"
      },
      "source": [
        "Tensor math and comaprison operation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2_Twks9uPjH",
        "outputId": "1331698f-8b0a-4df5-fd0c-069c604c55c1"
      },
      "source": [
        "x = torch.tensor([1,2,3])\n",
        "y = torch.tensor([9,8,7])\n",
        "#addition\n",
        "z1 = torch.empty(3)\n",
        "torch.add(x,y, out =z1)\n",
        "print(z1)\n",
        "\n",
        "z2 =  torch.add(x,y)\n",
        "print(z2)\n",
        "\n",
        "z = x + y #recommended one \n",
        "print(z)\n",
        "\n",
        "#substraction \n",
        "\n",
        "z = x-y\n",
        "print(z)\n",
        "\n",
        "#division\n",
        "\n",
        "z=torch.true_divide(x,y) # element wise division if both of them are of the same shape\n",
        "print(z)\n",
        "z = torch.true_divide(x,2) # division of each element by 2\n",
        "print(z)\n",
        "\n",
        "#implace operation\n",
        "\n",
        "t = torch.zeros(3)\n",
        "t.add_(x)\n",
        "t += x # t= t+x is no implace \n",
        "\n",
        "#exponenciation\n",
        "\n",
        "z =x.pow(2)\n",
        "print(z)\n",
        "z =x**2\n",
        "print(z)\n",
        "\n",
        "#simple comparison\n",
        "\n",
        "z = x > 0\n",
        "print(z)\n",
        "\n",
        "#matrix multiplication\n",
        "\n",
        "x1 = torch.rand((2,5))\n",
        "x2 = torch.rand((5,3))\n",
        "\n",
        "x3 = torch.mm(x1,x2) #element wise muliplication\n",
        "print(x3)\n",
        "\n",
        "x3 = x1.mm(x2)  #element wise multiplication \n",
        "print(x3)\n",
        "\n",
        "#matrix expoenetiation \n",
        "\n",
        "matrix_exp = torch.rand((5,5))\n",
        "print(matrix_exp.matrix_power(3)) # the shape is maintained \n",
        "\n",
        "#element wise multiplication \n",
        "\n",
        "z = x*y \n",
        "print(z)\n",
        "\n",
        "#dot product\n",
        "\n",
        "z = torch.dot(x,y) # Multiply each element and sum \n",
        "print(z)\n",
        "\n",
        "# batch matrix multiplication \n",
        "\n",
        "batch =32\n",
        "n = 10\n",
        "m = 20\n",
        "p = 30\n",
        "\n",
        "tensor1 = torch.rand(batch,n,m)\n",
        "tensor2 = torch.rand(batch,m,p)\n",
        "out_bmm = torch.bmm(tensor1,tensor2)  # shape would be batch , n , p\n",
        "\n",
        "# examples of broacasting \n",
        "\n",
        "x1 = torch.rand(5,5)\n",
        "x2 = torch.rand(1,5)\n",
        "\n",
        "z = x1-x2 #  the row of x2 would expand so that it matches with the row of x2 and there would be a batchwise substraction of each row of x2 from x1\n",
        "print(x1)\n",
        "print(x2)\n",
        "print(z)\n",
        "\n",
        "z = x1 ** x2\n",
        "\n",
        "print(z)\n",
        "\n",
        "# other useful tensor operations \n",
        "\n",
        "sum_x = torch.sum(x, dim = 0) #dim is the simention of a tensor in which we need to sum over \n",
        "print(sum_x)\n",
        "\n",
        "values,indices = torch.max(x,dim = 0) # can also do x.max(dim = 0)\n",
        "print(values, indices)\n",
        "values,indices = torch.min(x,dim = 0) # can also do x.min(dim = 0)\n",
        "print(values, indices)\n",
        "\n",
        "abs_x = torch.abs(x)  # can also do x.max()\n",
        "z = torch.argmax(x,dim = 0) # returns index of the one hwich is the maximum ; special case of the max function \n",
        "print(z)\n",
        "z = torch.argmin(x,dim = 0)\n",
        "print(z) \n",
        "\n",
        "mean_x = torch.mean(x.float(),dim = 0) # for mean the datatype should be float \n",
        "print(mean_x)\n",
        "\n",
        "z = torch.eq(x,y) # element wise see if the elements are equal \n",
        "print(z)\n",
        " \n",
        "sorted_y, indices = torch.sort(y, dim = 0, descending = False) # Sort in ascending order and also returns the indices which we need to swap \n",
        "print(indices) \n",
        "\n",
        "# clamp function \n",
        "\n",
        "# How the function works is it takes the vector x and all the values less than 0 are taken as zero \n",
        "# and all the values greater than ten(10) are taken as 10\n",
        "# ReLu is a special case of clamp function \n",
        "z =  torch.clamp(x, min = 0, max = 10)\n",
        "\n",
        "x = torch.tensor([1,0,1,1], dtype = torch.bool)\n",
        "z = torch.any(x) # returns true if nay of the value in x is true \n",
        "print(z)\n",
        "z = torch.all(x) # returns true if all of the values are true \n",
        "print(z)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([10., 10., 10.])\n",
            "tensor([10, 10, 10])\n",
            "tensor([10, 10, 10])\n",
            "tensor([-8, -6, -4])\n",
            "tensor([0.1111, 0.2500, 0.4286])\n",
            "tensor([0.5000, 1.0000, 1.5000])\n",
            "tensor([1, 4, 9])\n",
            "tensor([1, 4, 9])\n",
            "tensor([True, True, True])\n",
            "tensor([[1.7633, 2.1221, 2.2166],\n",
            "        [1.9693, 1.7481, 2.1166]])\n",
            "tensor([[1.7633, 2.1221, 2.2166],\n",
            "        [1.9693, 1.7481, 2.1166]])\n",
            "tensor([[2.1789, 3.4585, 2.4498, 2.6378, 1.9337],\n",
            "        [1.5661, 2.6530, 1.7624, 1.8398, 1.4510],\n",
            "        [2.4035, 3.9570, 2.6042, 2.8256, 2.1504],\n",
            "        [2.3166, 3.6886, 2.5509, 2.6682, 2.0378],\n",
            "        [2.3794, 3.5880, 2.5828, 2.8000, 1.9606]])\n",
            "tensor([ 9, 16, 21])\n",
            "tensor(46)\n",
            "tensor([[0.1850, 0.4252, 0.2628, 0.5987, 0.9797],\n",
            "        [0.1305, 0.3096, 0.2194, 0.2141, 0.9062],\n",
            "        [0.7981, 0.1307, 0.7868, 0.1401, 0.4079],\n",
            "        [0.5894, 0.5304, 0.2810, 0.3841, 0.7131],\n",
            "        [0.8090, 0.9887, 0.2893, 0.5090, 0.1732]])\n",
            "tensor([[0.5786, 0.2303, 0.3017, 0.7720, 0.1161]])\n",
            "tensor([[-0.3936,  0.1950, -0.0389, -0.1733,  0.8636],\n",
            "        [-0.4481,  0.0794, -0.0823, -0.5579,  0.7901],\n",
            "        [ 0.2195, -0.0995,  0.4851, -0.6318,  0.2919],\n",
            "        [ 0.0108,  0.3001, -0.0207, -0.3878,  0.5971],\n",
            "        [ 0.2303,  0.7584, -0.0124, -0.2629,  0.0571]])\n",
            "tensor([[0.3767, 0.8213, 0.6682, 0.6730, 0.9976],\n",
            "        [0.3079, 0.7634, 0.6328, 0.3043, 0.9886],\n",
            "        [0.8777, 0.6259, 0.9302, 0.2194, 0.9012],\n",
            "        [0.7365, 0.8641, 0.6818, 0.4778, 0.9615],\n",
            "        [0.8846, 0.9974, 0.6878, 0.5938, 0.8159]])\n",
            "tensor(6)\n",
            "tensor(3) tensor(2)\n",
            "tensor(1) tensor(0)\n",
            "tensor(2)\n",
            "tensor(0)\n",
            "tensor(2.)\n",
            "tensor([False, False, False])\n",
            "tensor([2, 1, 0])\n",
            "tensor(True)\n",
            "tensor(False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB70D5OPZAMS"
      },
      "source": [
        "Indexing in the tensor "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuw-asZ8u-XZ",
        "outputId": "e1ad5bf3-5673-4f0d-9239-38e2b3b0f7dd"
      },
      "source": [
        "batch_size = 10\n",
        "features = 25\n",
        "x = torch.rand(batch_size, features)\n",
        "print(x[0].shape)# x[0,:]\n",
        "\n",
        "print(x[:,0].shape)\n",
        "\n",
        "# how to get the first 10 features of the third example \n",
        "#2 = is the third example \n",
        "print(x[2,0:10])\n",
        "\n",
        "x[0,0] = 100\n",
        "\n",
        "# fancy indexing \n",
        "\n",
        "x =  torch.arange(10)\n",
        "indices = [2, 5, 8]\n",
        "print(x[indices]) # pick out the 2,5,8 element from the x\n",
        "\n",
        "x = torch.rand(3,5)\n",
        "rows = torch.tensor([1,0])\n",
        "col = torch.tensor([4,0])\n",
        "print(x[rows,col])\n",
        "\n",
        "#more advanced indexing \n",
        "\n",
        "x = torch.arange(10)\n",
        "\n",
        "print(x[(x<2)| (x >8) ])\n",
        "print(x[(x>2) & (x <8) ])\n",
        "\n",
        "print(x.remainder(2)==0)\n",
        "\n",
        "#useful operations\n",
        "\n",
        "print(torch.where(x>5,x,x*2)) # if it satisfies the condition then x otherwise 2*x\n",
        "print(torch.tensor([0,0,1,2,2,3,4]).unique()) #returns unique elements of a tensor\n",
        "print(x.ndimension()) #prints the number of dimention\n",
        "print(x.numel()) # count the number of elements in x \n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([25])\n",
            "torch.Size([10])\n",
            "tensor([0.8908, 0.2857, 0.7304, 0.2952, 0.8143, 0.1332, 0.2679, 0.9255, 0.7489,\n",
            "        0.7897])\n",
            "tensor([2, 5, 8])\n",
            "tensor([0.4432, 0.0144])\n",
            "tensor([0, 1, 9])\n",
            "tensor([3, 4, 5, 6, 7])\n",
            "tensor([ True, False,  True, False,  True, False,  True, False,  True, False])\n",
            "tensor([ 0,  2,  4,  6,  8, 10,  6,  7,  8,  9])\n",
            "tensor([0, 1, 2, 3, 4])\n",
            "1\n",
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iabsxPznoDz"
      },
      "source": [
        "Tensor reshaping "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYGXIMbHbFak",
        "outputId": "adfad719-86ce-4085-bffa-2854e8f20a71"
      },
      "source": [
        "x = torch.arange(9)\n",
        "\n",
        "x_3x3 = x.view(3,3) # superior as it does not have the data loss but could be appliedto continuous data memory\n",
        "print(x_3x3)\n",
        "\n",
        "x_3x3 = x.reshape(3,3) # would work everytime but there is data loss\n",
        "print(x_3x3)\n",
        "y = x_3x3.t()\n",
        "print(y)\n",
        "#print(y.view(9)) # we'll get the error as it's not intractable \n",
        "print(y.contiguous().view(9))\n",
        "\n",
        "x1 = torch.rand(2,5)\n",
        "x2 = torch.rand(2,5)\n",
        "\n",
        "print(torch.cat((x1,x2), dim =0).shape)\n",
        "print(torch.cat((x1,x2), dim =1).shape)\n",
        "\n",
        "z = x1.view(-1)\n",
        "print(z.shape)\n",
        "\n",
        "batch = 64\n",
        "x = torch.rand(batch,2,5)\n",
        "z = x.view(batch,-1)\n",
        "print(z.shape)\n",
        "\n",
        "#switching axis\n",
        "\n",
        "z = x.permute(0,2,1)\n",
        "print(z.shape)\n",
        "\n",
        "x = torch.arange(10)\n",
        "print(x.unsqueeze(1).shape)\n",
        "print(x.unsqueeze(1).shape)\n",
        "\n",
        "x = torch.arange(10).unsqueeze(0).unsqueeze(1) #1*1*10\n",
        "print(x)\n",
        "\n",
        "z =  x.squeeze(1)\n",
        "print(z.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "tensor([[0, 3, 6],\n",
            "        [1, 4, 7],\n",
            "        [2, 5, 8]])\n",
            "tensor([0, 3, 6, 1, 4, 7, 2, 5, 8])\n",
            "torch.Size([4, 5])\n",
            "torch.Size([2, 10])\n",
            "torch.Size([10])\n",
            "torch.Size([64, 10])\n",
            "torch.Size([64, 5, 2])\n",
            "torch.Size([10, 1])\n",
            "torch.Size([10, 1])\n",
            "tensor([[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]])\n",
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}